# Olympics 2024 Azure Data Engineering Project

## Overview

This repository showcases an end-to-end Azure Data Engineering project. It demonstrates the workflow of ingesting, transforming, and exporting data using Azure Data Factory, Spark, and Databricks. The project includes a Databricks notebook detailing each step in the data pipeline.

![image](https://github.com/user-attachments/assets/1221ab75-ae0a-4c09-a11d-5c463a68eb3f)




This project showcases an end-to-end data engineering solution for the Paris 2024 Olympics using Azure services. By leveraging the GitHub Student Pack, Iâ€™ve built a comprehensive data pipeline that ingests, processes, and visualizes data from this global event.

## Project Overview

### Data Ingestion

- **Azure Data Factory (ADF)**: Pipelines have been created to ingest data from various sources into Azure Data Lake Storage (ADLS). This setup includes data from sports events, athlete statistics, and venue information.

### Data Storage and Management

- **Azure Data Lake Storage (ADLS)**: Configured storage accounts to handle and organize data. Data is stored in both raw and processed formats, allowing for efficient data management and retrieval.

### Data Transformation

- **Azure Databricks**: Utilized Spark-based notebooks to clean, transform, and prepare the data. Python and Spark were employed for data normalization, feature engineering, and aggregations.
- **Python**: Custom scripts were used for specific data manipulation and processing tasks.
- **SQL**: Queries written to handle structured data transformations and aggregations.

### Data Warehousing and Analysis

- **Azure Synapse Analytics**: Set up a data warehouse for structured data. SQL queries have been written to analyze trends and extract key insights related to the Paris 2024 Olympics.

### Data Visualization

- **Power BI**: Interactive dashboards and reports have been developed to present data insights. These visualizations include event schedules, athlete performance metrics, and venue statistics.


## Technologies Used

- **Azure Data Factory (ADF)**
- **Azure Data Lake Storage (ADLS)**
- **Azure Databricks** (Python, Spark, SQL)
- **Azure Synapse Analytics** (SQL)
- **Power BI**

## How to Explore the Project

1. **Review the Data Pipelines**: Explore the Azure Data Factory pipelines used for data ingestion.
2. **Examine Data Storage**: Check out the organization and structure of data in Azure Data Lake Storage.
3. **Analyze Transformations**: Look at the Databricks notebooks for data cleaning and transformation processes.
4. **Explore Data Warehousing**: Dive into the data warehousing setup and SQL queries in Azure Synapse Analytics.
5. **Interact with Visualizations**: View the Power BI dashboards to see the data visualizations and insights generated from the analysis.


# Power BI Dashboard

![image](https://github.com/user-attachments/assets/f4e196dc-bfee-4a3f-a50c-11a02b546cbd)

![image](https://github.com/user-attachments/assets/09d19d19-1719-400c-b493-7ce3a523d542)

![image](https://github.com/user-attachments/assets/8a1dc77a-6191-4bea-a9dc-2e5c65b9a806)

![image](https://github.com/user-attachments/assets/3877b7c6-aa1f-4256-a743-39c985b6dc72)






