# Olympics 2024 Azure Data Engineering Project

## Overview

This repository showcases an end-to-end Azure Data Engineering project. It demonstrates the workflow of ingesting, transforming, and exporting data using Azure Data Factory, Spark, and Databricks. The project includes a Databricks notebook detailing each step in the data pipeline.

![image](https://github.com/user-attachments/assets/7378bf86-0b65-45fb-8405-9aa3069d53e2)


This project showcases an end-to-end data engineering solution for the Paris 2024 Olympics using Azure services. By leveraging the GitHub Student Pack, Iâ€™ve built a comprehensive data pipeline that ingests, processes, and visualizes data from this global event.

## Project Overview

### Data Ingestion

- **Azure Data Factory (ADF)**: Pipelines have been created to ingest data from various sources into Azure Data Lake Storage (ADLS). This setup includes data from sports events, athlete statistics, and venue information.

### Data Storage and Management

- **Azure Data Lake Storage (ADLS)**: Configured storage accounts to handle and organize data. Data is stored in both raw and processed formats, allowing for efficient data management and retrieval.

### Data Transformation

- **Azure Databricks**: Spark-based notebooks have been used to clean, transform, and prepare the data. This involves data normalization, feature engineering, and aggregations to make the data ready for analysis.

### Data Warehousing and Analysis

- **Azure Synapse Analytics**: Set up a data warehouse for structured data. SQL queries have been written to analyze trends and extract key insights related to the Paris 2024 Olympics.

### Data Visualization

- **Power BI**: Interactive dashboards and reports have been developed to present data insights. These visualizations include event schedules, athlete performance metrics, and venue statistics.


## Technologies Used

- **Azure Data Factory (ADF)**
- **Azure Data Lake Storage (ADLS)**
- **Azure Databricks**
- **Azure Synapse Analytics**
- **Power BI**

## How to Explore the Project

1. **Review the Data Pipelines**: Explore the Azure Data Factory pipelines used for data ingestion.
2. **Examine Data Storage**: Check out the organization and structure of data in Azure Data Lake Storage.
3. **Analyze Transformations**: Look at the Databricks notebooks for data cleaning and transformation processes.
4. **Explore Data Warehousing**: Dive into the data warehousing setup and SQL queries in Azure Synapse Analytics.
5. **Interact with Visualizations**: View the Power BI dashboards to see the data visualizations and insights generated from the analysis.

